\chapter{Introduction}

\section{Overview of Distributed Sensor Networks}
Distributed sensor networks (DSNs) consist of any number of sensors that collect and sense information about the environment around them. The sensors that make up these networks can either be homogeneous or heterogeneous. Distributed sensor networks are dynamic in that sensors can be added or removed from the network at any time. DSNs are also increasingly including mobile sensors as well. With the onset of the Internet of Things (IoT), itâ€™s easier than ever to build and deploy distributed sensor networks. Further, mobile devices, such as mobile phones, are seeing increased usage as intelligent sensing agents.

\subsection{DSN Data Collection Schemes}
Data can be collected from DSNs in various ways. Sensors can store data onboard to be collected manually or transmit data via a multitude of mediums (satellites, radio, laser, wired connections) using a slew of standards (TCP/IP, Zigbee, Bluetooth, custom, etc).

In some DSNs, data is routed between the sensors using various approaches % TODO cite this
and eventually makes its way to a sink or sinks. A sink is a data collection node. Cloud computing has become a prevalent choice for DSNs sinks since they often provide the ability to provision resources as needed. Various approached have been proposed that minimize and optimize communications between sensors within a DSN. % TODO Cite this

In other DSNs, sensor nodes have direct access to a sink, and instead of communicating with each other and passing messages among themselves, the nodes send their data directly to the sink. It's also possible that a DSN takes a hybrid approach and performs some communication within the network and some directly to the sink. 

Not only are there various approaches to routing data, but there are also various approaches to deciding what kind of data to send (or acquire). 

\subsection{DSN Detection Schemes}
On one extreme end we have the send everything approach where each sensor sends its data to the sink all the time (or at least when it has the means to do). In this scenario, the sink is responsible for collection, cleaning, detection, and classification of signals and events within the data. This approach can be bandwidth and energy intensive but provides the benefit of allowing more complete analysis to occur beyond the sink where more computational resources exist. This provides more accurate results and allows the sink to examine the results in aggregate with the rest of the DSN.

The other extreme is that sensors only send data when they have detected a signal of interest. In this scenario, sensors use onboard computing capabilities to filter their sensor stream and perform signal detection on the device. Only when the devices make a detection do they send the detection or data stream to a sink for further processing. This minimizes bandwidth but detection and classification of signals must occur with more constrained computing and energy environments. Further, the global state of the network can't be known without adding the complexity of sensor-to-sensor communication.

Often time a hybrid approach is taken where low fidelity feature extracted and sometimes aggregate data is send from the sensors to the sink. The sink analyzes the low fidelity feature extracted stream to determine if raw data should be requested from the sensors. The act of requesting data from the sensors is called triggering. This approach is useful because we still gain bandwidth benefits and can easily get a sensor for the global state of a network.

With all of these factors combined, management, collection, detection, localization, and analysis from distributed sensor networks is not a trivial task. The data collected from distributed sensor networks under certain circumstances is considered Big Data. 

\subsection{DSNs as Big Data}
Big Data is generally defined by the four V's; volume, velocity, variety, and value. These characteristics can be observed in many of the DSNs that exist and are being created today. % TODO more citations

That is, distributed sensor networks create a large volume of data due to the abundance of IoT and mobile devices that make up DSNs. As communication infrastructures improve and hardware becomes smaller, smarter and more energy efficient, sensors are able to send and transfer larger amounts of data.

Distributed sensor networks create a variety of data with different formats and data quality issues. Distributed sensor networks can produce data at high velocity. These characteristics of data produced from distributed sensor networks create a need for efficient architectures and specific algorithms designed for working with Big Data.

Further, sensor networks are often constrained in both computing power and available energy sources. This forces us to find comprises between data collection, onboard sensor processing, sensor communication, and network coordination.

This proposal focuses on identifying and tuning several aspects of distributed sensor networks.

Triggering is the act of monitoring low fidelity feature extracted data and triggering sensors for high fidelity data streams when abnormalities are seen in the triggering data stream.

Detection is the algorithmic ability to detect signals of interest among a sea of background noise. Sensor networks often detect signals without knowing what they are or how to classify them. 

Classification is the act of associating a signal with a known designation. 

\subsection{Distributed Sensor Networks and Big Data}

\section{The Data Management and Analysis Problems}

\section{Traditional Approaches to Data Management and Analysis}

\section{Seven proposed benefits of Laha} \label{laha-benefits}
\subsection{Tiered management of Big Data}
\subsection{Automatically provide context to classified incidents}
\subsection{Adaptive optimizations for detection and classification}
\subsection{Adaptive optimizations for triggering}
\subsection{Provides a model of underlying sensor field topology}
\subsection{Decreased bandwidth of entire DDS}
\subsection{Decreased energy usage from optimized communications and analysis}

\section{Evaluation of Laha}
\subsection{Design and implement Laha-compliant software reference implementations (OPQMauka and Lokahi)}
OPQMauka is a distributed, plugin-based middleware component of the Open Power Quality (OPQ) software stack that provides higher level analytics and data management for a distributed PQ network.

\subsection{Deploy Laha reference implementations on test sites}
\subsection{Validate data collected by Laha deployment}
\subsection{Use Laha deployment to evaluate each of the seven proposed benefits discussed in section \ref{laha-benefits}}

\section{Anticipated contributions of this thesis}
\subsection{Laha design: a novel distributed sensor network adaptive design with seven useful properties}
\subsection{Laha evaluation: empirical data to confirm or deny the seven useful properties}
\subsection{OPQMauka and Lokahi: reference implementations of Laha}
\subsection{Implications for modern distributed sensor networks}

\section{Timeline}
\subsection{2018 Q4: Implement, deploy, and validate Laha reference implementations}
\subsection{2019 Q1: Begin validated data collection}
\subsection{2019 Q2: Continue validated data collection, thesis chapters 1-3}
\subsection{2019 Q3: Finish validated data collection, these chapters 4-6}





